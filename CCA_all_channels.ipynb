{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn.cross_decomposition import CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para armazenar os dados\n",
    "original = {}\n",
    "\n",
    "# Path para o file com os dados\n",
    "directory = \"Data_trials\"\n",
    "\n",
    "# Iterar através de cada pasta de participante\n",
    "for participant_folder in os.listdir(directory):\n",
    "    participant_path = os.path.join(directory, participant_folder)\n",
    "    if os.path.isdir(participant_path):\n",
    "        participant_number = participant_folder[1:]  # Extrair número do participante do nome da pasta\n",
    "\n",
    "        # Iterar através dos arquivos MATLAB na pasta do participante\n",
    "        for file_name in os.listdir(participant_path):\n",
    "            if file_name.endswith(\".mat\") and not file_name.endswith((\"5.mat\", \"6.mat\")):\n",
    "                file_path = os.path.join(participant_path, file_name)\n",
    "\n",
    "                # Carregar arquivo MATLAB\n",
    "                mat_data = loadmat(file_path)\n",
    "\n",
    "                # Selecionar a key com o nome do file\n",
    "                keys = mat_data.keys()\n",
    "                key = list(keys)[3]\n",
    "\n",
    "                # Criar DataFrame a partir dos dados; .T para transformar linhas em colunas\n",
    "                df = pd.DataFrame(mat_data[key].T, columns=['TimeStamps','PO3', 'POz', 'PO4', 'O1', 'Oz', 'O2'])\n",
    "\n",
    "                # Adicionar os dados ao dicionário usando o nome da variável como chave\n",
    "                if key not in original:\n",
    "                    original[key] = []\n",
    "                original[key].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency = 512.0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Cálculo da frequência de amostragem\n",
    "\n",
    "data = original['P01_T1_R1_1'][0]\n",
    "time_diff = data['TimeStamps'].diff().mean()\n",
    "fs = 1 / time_diff\n",
    "print(\"Sampling frequency =\", fs, \"Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_to_trim = int(0.5 * fs)\n",
    "\n",
    "for key, dfs in original.items():\n",
    "    trimmed_dfs = []\n",
    "    for df in dfs:\n",
    "        df_trimmed = df.iloc[num_samples_to_trim:-(num_samples_to_trim)].reset_index(drop=True)\n",
    "        trimmed_dfs.append(df_trimmed)\n",
    "    original[key] = trimmed_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição de parâmetros dos filtros\n",
    "notch_freq = 50.0 \n",
    "quality_factor = 40.0\n",
    "highcut = 20\n",
    "order = 8\n",
    "lowcut = 5\n",
    "\n",
    "#Lowpass & Notch\n",
    "sos = signal.iirfilter(order, highcut, btype='lowpass', analog=False, ftype='butter', fs=fs, output='sos')\n",
    "b_notch, a_notch = signal.iirnotch(notch_freq, quality_factor, fs)\n",
    "b_hp, a_hp = signal.butter(order, lowcut, btype='highpass', fs=fs)\n",
    "\n",
    "#Dataframe com os dados filtrados\n",
    "filtrado= {}\n",
    "\n",
    "#Aplicação do low pass filter\n",
    "for key, dfs in original.items():\n",
    "    filtrado[key] = []\n",
    "    for df in dfs:\n",
    "        timestamps = df['TimeStamps']\n",
    "        df_without_timestamps = df.drop(columns=['TimeStamps'])\n",
    "        df_filtrado_lp = pd.DataFrame(signal.sosfiltfilt(sos, df_without_timestamps.values, axis=0), columns=df_without_timestamps.columns)\n",
    "        df_filtrado_lphp = pd.DataFrame(signal.filtfilt(b_hp, a_hp, df_filtrado_lp.values, axis=0), columns=df_without_timestamps.columns)\n",
    "        df_filtrado = pd.concat([timestamps, df_filtrado_lphp], axis=1)\n",
    "        filtrado[key].append(df_filtrado)\n",
    "\n",
    "#Aplicação do notch filter\n",
    "for key, dfs in filtrado.items():\n",
    "    for df in dfs:\n",
    "        for column in df.columns[1:]:\n",
    "            df[column] = signal.filtfilt(b_notch, a_notch, df[column])\n",
    "\n",
    "#Oz filtrado\n",
    "filtered_channels = {}\n",
    "for key, dfs in filtrado.items():\n",
    "    filtered_channels[key] = []\n",
    "    for df in dfs:\n",
    "        df_without_timestamps = df.drop(columns=['TimeStamps'])\n",
    "        filtered_channels[key].append(df_without_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, dfs in filtered_channels.items():\n",
    "    for df in dfs:\n",
    "        for channel in df:\n",
    "            first_matrix = np.array(df[channel]).T\n",
    "            X = first_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 8)\n"
     ]
    }
   ],
   "source": [
    "# Creating the time series windows\n",
    "window_size = X.shape[0] # Assuming you want the same window size as the first matrix's rows\n",
    "t = np.linspace(0, 4, window_size, endpoint=False)\n",
    "\n",
    "# Generating sine and cosine reference signals\n",
    "frequencies = [7, 11, 13, 17]\n",
    "reference_signals = []\n",
    "for freq in frequencies:\n",
    "    sine_wave = 10 * np.sin(2 * np.pi * freq * t)\n",
    "    cosine_wave = 10 * np.cos(2 * np.pi * freq * t)\n",
    "    reference_signals.append(sine_wave)\n",
    "    reference_signals.append(cosine_wave)\n",
    "ref = np.array(reference_signals).T\n",
    "print(ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular as correlações\n",
    "def calculate_correlations(matrix, reference_signals):\n",
    "    cca = CCA(n_components=1)  # Defina o número de componentes canônicos\n",
    "    Correlation = []\n",
    "\n",
    "    for ref_signal in reference_signals:\n",
    "        # Ajustar o CCA aos dados\n",
    "        cca.fit(matrix, ref_signal)\n",
    "        # Transformar os dados usando o CCA\n",
    "        x1, x2 = cca.transform(matrix, ref_signal)\n",
    "        corr = np.corrcoef(x1.T, x2.T)[0, 1]\n",
    "        Correlation.append(corr)\n",
    "    \n",
    "    return Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de trials: 560\n",
      "Total de respostas corretas: 380\n",
      "Accuracy: 67.86%\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre todas as chaves em oz_filtered e calcular as correlações\n",
    "all_correlations = {}\n",
    "\n",
    "total_correct = 0\n",
    "total_trials = 0\n",
    "\n",
    "for key in filtered_channels:\n",
    "    # if key == \"P01_T1_R1_1\":\n",
    "    for df in filtered_channels[key]:\n",
    "        correlation_totals = []\n",
    "        matrix = np.array(df).T\n",
    "        for i in range(matrix.shape[0]):\n",
    "            column = matrix[i, :][np.newaxis, :]\n",
    "            column = column.T\n",
    "            correlations = calculate_correlations(column, reference_signals)\n",
    "            correlation_totals.append(correlations)\n",
    "        average_correlations = np.mean(correlation_totals, axis=0)\n",
    "        max_correlation_index = np.argmax(average_correlations)// 2  # Índice da coluna com o valor máximo\n",
    "        all_correlations[key] = {'average correlations': average_correlations, 'max_correlation_index': max_correlation_index + 1}\n",
    "        # print('average correlations:', average_correlations, 'max_correlation_index:', max_correlation_index)\n",
    "    \n",
    "    last_character = key[-1]\n",
    "    if str(max_correlation_index+1) == last_character:  # Comparar com o último caractere\n",
    "        total_correct += 1\n",
    "    total_trials += 1\n",
    "\n",
    "# Calcular a accuracy\n",
    "accuracy = total_correct / total_trials\n",
    "\n",
    "# # Exibir as correlações\n",
    "# for key, correlations in all_correlations.items():\n",
    "#     print(f\"{key}: {all_correlations[key]}\")\n",
    "\n",
    "print(f\"Total de trials: {total_trials}\")\n",
    "print(f\"Total de respostas corretas: {total_correct}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
