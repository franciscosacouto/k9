{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn.cross_decomposition import CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for original data\n",
    "original = {}\n",
    "\n",
    "# File path\n",
    "directory = \"Data_trials\"\n",
    "\n",
    "for participant_folder in os.listdir(directory):\n",
    "    participant_path = os.path.join(directory, participant_folder)\n",
    "    if os.path.isdir(participant_path):\n",
    "        participant_number = participant_folder[1:]  # Extract participant numbers from folder\n",
    "\n",
    "        for file_name in os.listdir(participant_path):\n",
    "            if file_name.endswith(\".mat\") and not file_name.endswith((\"5.mat\", \"6.mat\")):\n",
    "                file_path = os.path.join(participant_path, file_name)\n",
    "\n",
    "                mat_data = loadmat(file_path)\n",
    "\n",
    "                keys = mat_data.keys()\n",
    "                key = list(keys)[3]\n",
    "\n",
    "                # Create dataframe\n",
    "                df = pd.DataFrame(mat_data[key].T, columns=['TimeStamps','PO3', 'POz', 'PO4', 'O1', 'Oz', 'O2'])\n",
    "\n",
    "                # Add data to the dictionary\n",
    "                if key not in original:\n",
    "                    original[key] = []\n",
    "                original[key].append(df)\n",
    "\n",
    "#Oz channel\n",
    "oz = {}\n",
    "for key, dfs in original.items():\n",
    "    oz[key] = []\n",
    "    for df in dfs:\n",
    "        oz_data = df['Oz']\n",
    "        oz[key].append(oz_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling frequency calculation\n",
    "\n",
    "data = original['P01_T1_R1_1'][0]\n",
    "time_diff = data['TimeStamps'].diff().mean()\n",
    "fs = 1 / time_diff\n",
    "print(\"Sampling frequency =\", fs, \"Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trim EEg signal without stimulous (First and Last half second)\n",
    "\n",
    "num_samples_to_trim = int(0.5 * fs)\n",
    "\n",
    "for key, dfs in original.items():\n",
    "    trimmed_dfs = []\n",
    "    for df in dfs:\n",
    "        df_trimmed = df.iloc[num_samples_to_trim:-(num_samples_to_trim)].reset_index(drop=True)\n",
    "        trimmed_dfs.append(df_trimmed)\n",
    "    original[key] = trimmed_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr치ficos relativos apenas um gr치fico do ensaio 1 do teste 1 do paciente 1\n",
    "for key, dfs in oz.items():\n",
    "    if key == \"P01_T1_R1_1\":\n",
    "        plt.title(f'{key}_Oz')\n",
    "        for data in dfs:\n",
    "            data_subset = data.iloc[:200]\n",
    "            plt.plot(data_subset)\n",
    "        plt.xlabel('TimeStamps')\n",
    "        plt.ylabel('Valor')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filters parameters\n",
    "notch_freq = 50.0 \n",
    "quality_factor = 40.0\n",
    "highcut = 20\n",
    "order = 8\n",
    "lowcut = 5\n",
    "\n",
    "#Lowpass, Highpass and Notch\n",
    "sos = signal.iirfilter(order, highcut, btype='lowpass', analog=False, ftype='butter', fs=fs, output='sos')\n",
    "b_notch, a_notch = signal.iirnotch(notch_freq, quality_factor, fs)\n",
    "b_hp, a_hp = signal.butter(order, lowcut, btype='highpass', fs=fs)\n",
    "\n",
    "#Dictionary for filtered data\n",
    "filtrado= {}\n",
    "\n",
    "#Low and High pass filter application\n",
    "for key, dfs in original.items():\n",
    "    filtrado[key] = []\n",
    "    for df in dfs:\n",
    "        timestamps = df['TimeStamps']\n",
    "        df_without_timestamps = df.drop(columns=['TimeStamps'])\n",
    "        df_filtrado_lp = pd.DataFrame(signal.sosfiltfilt(sos, df_without_timestamps.values, axis=0), columns=df_without_timestamps.columns)\n",
    "        df_filtrado_lphp = pd.DataFrame(signal.filtfilt(b_hp, a_hp, df_filtrado_lp.values, axis=0), columns=df_without_timestamps.columns)\n",
    "        df_filtrado = pd.concat([timestamps, df_filtrado_lphp], axis=1)\n",
    "        filtrado[key].append(df_filtrado)\n",
    "\n",
    "#Notch filter application\n",
    "for key, dfs in filtrado.items():\n",
    "    for df in dfs:\n",
    "        for column in df.columns[1:]:\n",
    "            df[column] = signal.filtfilt(b_notch, a_notch, df[column])\n",
    "\n",
    "#Filtered Oz channel\n",
    "oz_filtered = {}\n",
    "for key, dfs in filtrado.items():\n",
    "    oz_filtered[key] = []\n",
    "    for df in dfs:\n",
    "        oz_filtered_data = df['Oz']\n",
    "        oz_filtered[key].append(oz_filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr치ficos relativos apenas um gr치fico do ensaio 1 do teste 1 do paciente 1\n",
    "for key, dfs in oz_filtered.items():\n",
    "    if key == \"P01_T1_R1_1\":\n",
    "        plt.title(f'{key}_Oz')\n",
    "        for data in dfs:\n",
    "            data_subset = data.iloc[:200]\n",
    "            plt.plot(data_subset)\n",
    "        plt.xlabel('TimeStamps')\n",
    "        plt.ylabel('Valor')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first key data\n",
    "first_key = list(oz_filtered.keys())[0]\n",
    "first_matrix = np.array(oz_filtered[first_key])\n",
    "X = first_matrix.T\n",
    "\n",
    "# Creating the time series windows\n",
    "window_size = X.shape[0] \n",
    "t = np.linspace(0, 4, window_size, endpoint=False)\n",
    "\n",
    "# Generating sine and cosine reference signals\n",
    "frequencies = [7, 11, 13, 17]\n",
    "reference_signals = []\n",
    "for freq in frequencies:\n",
    "    sine_wave = 10 * np.sin(2 * np.pi * freq * t)\n",
    "    cosine_wave = 10 * np.cos(2 * np.pi * freq * t)\n",
    "    reference_signals.append(sine_wave)\n",
    "    reference_signals.append(cosine_wave)\n",
    "\n",
    "ref = np.array(reference_signals).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations calculation Function\n",
    "def calculate_correlations(matrix, reference_signals):\n",
    "    cca = CCA(n_components=1)  # Canonic components number\n",
    "    Correlation = []\n",
    "\n",
    "    for ref_signal in reference_signals:\n",
    "        cca.fit(matrix, ref_signal)\n",
    "        x1, x2 = cca.transform(matrix, ref_signal)\n",
    "        corr = np.corrcoef(x1.T, x2.T)[0, 1]\n",
    "        Correlation.append(corr)\n",
    "    \n",
    "    return Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_correlations = {}\n",
    "\n",
    "total_correct = 0\n",
    "total_trials = 0\n",
    "\n",
    "for key in oz_filtered:\n",
    "    matrix = np.array(oz_filtered[key]).T\n",
    "    correlations = calculate_correlations(matrix, reference_signals)\n",
    "    max_correlation_index = np.argmax(correlations)\n",
    "    all_correlations[key] = {'correlations': correlations, 'max_correlation_index': max_correlation_index // 2 + 1}\n",
    "    \n",
    "    last_character = key[-1]\n",
    "    if str(max_correlation_index // 2 +1) == last_character:\n",
    "        total_correct += 1\n",
    "    total_trials += 1\n",
    "\n",
    "# Accuracy\n",
    "accuracy = total_correct / total_trials\n",
    "\n",
    "for key, correlations in all_correlations.items():\n",
    "    print(f\"{key}: {all_correlations[key]}\")\n",
    "\n",
    "print(f\"Total de trials: {total_trials}\")\n",
    "print(f\"Total de respostas corretas: {total_correct}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
